{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Table,Column,Integer,String\n",
    "import glob\n",
    "import os\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy.orm import mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=create_engine('sqlite:///new.sqlite',echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session=sessionmaker(bind=engine)\n",
    "session=Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base=declarative_base()\n",
    "\n",
    "#Create a metadata instance\n",
    "#A metadata is an object container that will store attributes and name of table \n",
    "metadata=MetaData(engine)\n",
    "\n",
    "#Define structure of table\n",
    "class product_table(object):\n",
    "    def __init__(self,number,description,ref_des):\n",
    "        self.product_id=product_id\n",
    "        self.station=station\n",
    "        self.time=time\n",
    "        self.result=result\n",
    "        self.employee_id=employee_id\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.product_id,self.station,self.time,self.result,self.employee_id}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_definition(table_name):\n",
    "    #Define table structure, here table_name varies\n",
    "    #We want to make table_define available outside function so we declare it as a function attribute\n",
    "    table_definition.table_define=Table(table_name,metadata,\n",
    "    Column('id',Integer,primary_key=True),\n",
    "    Column('product_id',String),\n",
    "    Column('station',String),\n",
    "    Column('time',String),\n",
    "    Column('result',String),\n",
    "    Column('employee_id',String)\n",
    "    )\n",
    "    \n",
    "    #Create table\n",
    "    #Note that we used the engine from function\n",
    "    metadata.create_all(engine)\n",
    "    \n",
    "    #Use mapper to define components of class as well as table definition together at once\n",
    "    mapper(product_table,table_definition.table_define,non_primary=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Mapper at 0x7fa638ac5e50; product_table>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_define_dummy=Table('dummy_table',metadata,\n",
    "Column('id',Integer,primary_key=True),\n",
    "Column('product_id',String),\n",
    "Column('station',String),\n",
    "Column('time',String),\n",
    "Column('result',String),\n",
    "Column('employee_id',String)\n",
    ")\n",
    "\n",
    "#Create table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "#Use mapper to define components of class as well as table definition together at once\n",
    "mapper(product_table,table_define_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('phd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Class '<class '__main__.product_table'>' already has a primary mapper defined. Use non_primary=True to create a non primary Mapper.  clear_mappers() will remove *all* current mappers from all classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-08d7dab93040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Use mapper to define components of class as well as table definition together at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable_define_dummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#This function will create a separate table for each csv file, if you have multiple csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mmapper\u001b[0;34m(class_, local_table, properties, primary_key, non_primary, inherits, inherit_condition, inherit_foreign_keys, extension, order_by, always_refresh, version_id_col, version_id_generator, polymorphic_on, _polymorphic_map, polymorphic_identity, concrete, with_polymorphic, polymorphic_load, allow_partial_pks, batch, column_prefix, include_properties, exclude_properties, passive_updates, passive_deletes, confirm_deleted_rows, eager_defaults, legacy_is_orphan, _compiled_cache_size)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/orm/mapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, class_, local_table, properties, primary_key, non_primary, inherits, inherit_condition, inherit_foreign_keys, extension, order_by, always_refresh, version_id_col, version_id_generator, polymorphic_on, _polymorphic_map, polymorphic_identity, concrete, with_polymorphic, polymorphic_load, allow_partial_pks, batch, column_prefix, include_properties, exclude_properties, passive_updates, passive_deletes, confirm_deleted_rows, eager_defaults, legacy_is_orphan, _compiled_cache_size)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_inheritance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_legacy_instrument_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_class_instrumentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_listeners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/orm/mapper.py\u001b[0m in \u001b[0;36m_configure_class_instrumentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                     \u001b[0;34m\"create a non primary Mapper.  clear_mappers() will \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                     \u001b[0;34m\"remove *all* current mappers from all classes.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m                     self.class_)\n\u001b[0m\u001b[1;32m   1217\u001b[0m             \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# a ClassManager may already exist as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: Class '<class '__main__.product_table'>' already has a primary mapper defined. Use non_primary=True to create a non primary Mapper.  clear_mappers() will remove *all* current mappers from all classes."
     ]
    }
   ],
   "source": [
    "metadata.create_all(engine)\n",
    "\n",
    "#Use mapper to define components of class as well as table definition together at once\n",
    "mapper(product_table,table_define_dummy)\n",
    "\n",
    "#This function will create a separate table for each csv file, if you have multiple csv files\n",
    "#Name of table will be extracted from file name. File name contains product name. \n",
    "#Each table will be identified by product name\n",
    "# It will read each excel file in the folder and insert bom into table\n",
    "def create_table(folder_of_files):\n",
    "    \n",
    "    #Get list of files in folder\n",
    "    files=glob.glob(os.path.join(folder_of_files,\"*.csv\"))\n",
    "    \n",
    "    \n",
    "    #Loop through all files in list\n",
    "    for file_name in files:\n",
    "        \n",
    "        #Read file into dataframe\n",
    "        csv_data=pd.read_csv(file_name)\n",
    "        \n",
    "        #Convert dataframe to list and store in same variable\n",
    "        csv_data=csv_data.values.tolist()\n",
    "        \n",
    "        #Get table name from file name. This will be our table name. \n",
    "        table_name_from_file=file_name.split('/')[8][:-4]\n",
    "        \n",
    "        \n",
    "        #Use table_definition function to define table structure\n",
    "        table_definition(table_name_from_file)\n",
    "        \n",
    "        #Loop through list of lists, each list in create_bom_table.xls_data is a row\n",
    "        for row in csv_data:\n",
    "            \n",
    "            #Each element in the list is an attribute for the table class\n",
    "            #Iterating through rows and inserting into table\n",
    "            ins=table_definition.table_define.insert().values(\n",
    "            product_id=row[0],station=row[1],time=row[2],result=row[3],employee_id=row[4])\n",
    "            conn=engine.connect()\n",
    "            conn.execute(ins)\n",
    "            \n",
    "\n",
    "#Calling function, argument is path of folder where all CSV files are stored\n",
    "create_table(\"path of folder where csv files are stored\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    S.No.  View Application Ref. No. Submission Date Payment Status    Fee  \\\n",
       "0      1  View    IITKPG2¥Ph.D¥EE¥1        25/10/19       Complete  400.0   \n",
       "1      2  View    IITKPG2¥Ph.D¥EE¥2       3/10/2019       Complete  400.0   \n",
       "2      3  View    IITKPG2¥Ph.D¥EE¥3        18/10/19       Complete  200.0   \n",
       "3      4  View    IITKPG2¥Ph.D¥EE¥4       3/10/2019       Complete  400.0   \n",
       "4      5  View    IITKPG2¥Ph.D¥EE¥5       3/10/2019       Complete  400.0   \n",
       "5      6  View    IITKPG2¥Ph.D¥EE¥6       3/10/2019       Complete  400.0   \n",
       "6      7  View    IITKPG2¥Ph.D¥EE¥7       9/10/2019       Complete  400.0   \n",
       "7      8  View    IITKPG2¥Ph.D¥EE¥8        30/10/19       Complete  400.0   \n",
       "8      9  View    IITKPG2¥Ph.D¥EE¥9       4/10/2019     Incomplete    NaN   \n",
       "9     10  View   IITKPG2¥Ph.D¥EE¥10        26/10/19       Complete  200.0   \n",
       "\n",
       "   Payment Date   Name  Gender       DOB  ... PE 2 Percentage PE 2 Rank  \\\n",
       "0           NaN   vbn1    Male  21/11/94  ...            74.0       NaN   \n",
       "1           NaN   vbn2    Male  18/10/93  ...            55.0       NaN   \n",
       "2           NaN   vbn3    Male  21/11/95  ...            70.8       NaN   \n",
       "3           NaN   vbn4  Female  18/10/94  ...            75.4       NaN   \n",
       "4           NaN   vbn5    Male  21/11/96  ...            57.8       NaN   \n",
       "5           NaN   vbn6  Female  18/10/95  ...            74.0       NaN   \n",
       "6           NaN   vbn7    Male  21/11/95  ...            75.4       NaN   \n",
       "7           NaN   vbn8    Male  18/10/94  ...            57.8       NaN   \n",
       "8           NaN   vbn9    Male  21/11/96  ...            74.0       NaN   \n",
       "9           NaN  vbn10    Male  18/10/95  ...            57.8       NaN   \n",
       "\n",
       "                                     PE 3 Degree  PE 3 Year  \\\n",
       "0                               Bachelors Degree     2016.0   \n",
       "1                        Secondary or equivalent     2010.0   \n",
       "2                                            NaN        NaN   \n",
       "3                               Bachelors Degree     2015.0   \n",
       "4  BE/BTech - Bachelor of Engineering/Technology     2016.0   \n",
       "5                               Bachelors Degree     2012.0   \n",
       "6                               Bachelors Degree     2002.0   \n",
       "7  BE/BTech - Bachelor of Engineering/Technology     2016.0   \n",
       "8                               Bachelors Degree     2017.0   \n",
       "9                               Bachelors Degree     2014.0   \n",
       "\n",
       "                             PE 3 Board / University  \\\n",
       "0  MAULANA ABUL KALAM AZAD UNIVERSITY OF TECHNOLO...   \n",
       "1                                               CBSE   \n",
       "2                                                NaN   \n",
       "3                                                SOA   \n",
       "4                          IGIT Sarang / BPUT Orissa   \n",
       "5                                              MJPRU   \n",
       "6  UNIVERSITY OF MADRAS / SRI VENKATESWARA COLLEG...   \n",
       "7                                                AMU   \n",
       "8                                     SRMCEM LUCKNOW   \n",
       "9                    Uttrakhand Technical University   \n",
       "\n",
       "                                       PE 3 Subjects  PE 3 Score  \\\n",
       "0                             ELECTRICAL ENGINEERING        8.32   \n",
       "1  ENGLISH COMM., HINDI COURSE-A, MATHEMATICS, SC...        8.15   \n",
       "2                                                NaN        7.89   \n",
       "3                                                 EE     3421.00   \n",
       "4                             Electrical Engineering        8.50   \n",
       "5                             Electrical Engineering        8.32   \n",
       "6             ELECTRICAL AND ELECTRONICS ENGINEERING        8.15   \n",
       "7                             ELECTRICAL ENGINEERING        7.89   \n",
       "8                             ELECTRICAL ENGINEERING     3421.00   \n",
       "9                                                ECE        8.50   \n",
       "\n",
       "  PE 3 Max Score PE 3 Percentage PE 3 Rank  \n",
       "0             10           80.00       NaN  \n",
       "1             10           81.50       NaN  \n",
       "2             10           71.40       NaN  \n",
       "3           4700           72.79       NaN  \n",
       "4             10           85.00       NaN  \n",
       "5             10           80.00       NaN  \n",
       "6             10           81.50       NaN  \n",
       "7             10           71.40       NaN  \n",
       "8           4700           72.79       NaN  \n",
       "9             10           85.00       NaN  \n",
       "\n",
       "[10 rows x 125 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
